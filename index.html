<<<<<<< HEAD
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <title>Chia-Hsiang Kao (高家祥)</title>

  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">
  <meta content="Chia-Hsiang Kao, 高家祥, Robust and interpretable Machine Learning." name="keywords" />
  <meta content="I'm a Medical Doctor, and an admitted CS Ph.D. student at Cornell University." name="description" />
  <meta property="og:title" content="Chia-Hsiang's (家祥) Website" />
  <meta property="og:description" content="My goal is to develop robust, reliable, and interpretable ML algorithms and healthcare systems." />
  <meta property="og:image" content="https://raw.githubusercontent.com/IandRover/IandRover.github.io/gh-pages/assets/img/hero-small.webp" />
  <meta property="og:type" content="website" />
  <meta property="og:url" content="https://iandrover.github.io/" />

  <style type="text/css">
  /* Design Credits: Jon Barron and Abhishek Kar and Saurabh Gupta*/
  a {
  color: #1772d0;
  text-decoration:none;
  }
  a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
  }
  body,td,th {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 400
  }
  heading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 19px;
    font-weight: 1000
  }
  strong {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 800
  }
  strongred {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    color: 'red' ;
    font-size: 16px
  }
  sectionheading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    font-weight: 600
  }
  pageheading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 38px;
    font-weight: 400
  }
  </style>
  <link rel="icon" type="image/png" href="images/icon.png">
  <script type="text/javascript" src="js/hidebib.js"></script>
  <title>Chia-Hsiang Kao</title>
  <meta name="Chia-Hsiang Kao's Homepage" http-equiv="Content-Type" content="Chia-Hsiang Kao's Homepage">
  <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,300' rel='stylesheet' type='text/css'>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-GVN6RWCQKV"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-GVN6RWCQKV');
  </script>
  <!-- End : Google Analytics Code -->
  <script src="js/scramble.js"></script>
  <link rel="stylesheet" href="/css/main.css" />

</head>

<body>
<table width="840" border="0" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr><td>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <p align="center">
    <!-- <font size="7">Chia-Hsiang Kao</font><br> -->
    <pageheading>Chia-Hsiang Kao (高家祥)</pageheading><br>
    <b>Email</b>: chkao.md04_at_nycu.edu.tw
    <br>
    <b>Email</b>: ck696_at_cornell.edu
    <font id="email" style="display:inline;">
      <noscript><i>Please enable Javascript to view</i></noscript>
    </font>
  </p>

  <tr>
    <!-- <td width="25%" valign="top"><a href="assets/img/Aaron_600x600.webp"><img src="assets/img/Aaron_600x600.webp" width="100%" style="border-radius:15px"></a> -->
    <td width="33%" valign="top"><a href="assets/img/Aaron[2308-2].png"><img src="assets/img/Aaron[2308-2].png" width="100%" style="border-radius:15px"></a>
        <p align=center>
            | <a href="https://iandrover.github.io/data/cv.pdf" target="_blank">CV</a> |
            <a href="https://github.com/IandRover" target="_blank">Github</a> |
            <a href="https://scholar.google.com.tw/citations?user=W_i9B0sAAAAJ" target="_blank">Google Scholar</a> |
        </p>
    </td>

    <td width="66%" valign="top" align="justify">
        <p>
            Hello, I'm a first-year Ph.D. student in Computer Science at Cornell University, and I also hold a medical license in Taiwan.
            <br>
            <br>
            I've had the privilege of collaborating with Dr. <a href="https://sites.google.com/site/pinyuchenpage" target="_blank">Pin-Yu Chen</a> at MTI-IBM Watson AI Lab, Prof. <a href="https://walonchiu.github.io/" target="_blank">Wei-Chen Chiu</a> and Prof. <a href="https://bml.ym.edu.tw/ibs/Members/LFChen-e.html" target="_blank">Li-Fen Chen</a> at NYCU, as well as NVIDIA Research Director Prof. <a href="http://vllab.ee.ntu.edu.tw/" target="_blank">Yu-Chiang Frank Wang</a>.
            <br>
            <br>
            My primary research interest lies in understanding the underlying mechanisms and implicit inductive biases of machine learning models and algorithms. I aspire to contribute to the development of robust and interpretable machine learning systems, designed to excel in challenging conditions.
        </p>
        <br>
    </td>

  </tr>
</table>

<table width="100%" align="center" style="margin-bottom:30px" cellspacing="0" cellpadding="0" border="0">
  <tbody><tr>
<!--       <th width="15%" valign="top" align="center">
      <a href="https://www.mediatek.com/" target="_blank"><img src="assets/logo_mediatek.png" alt="sym" width="45%"></a>
      <p style="line-height:1.3; font-size:12pt">MediaTek<br>AI Researcher<br>Jun. 22 - Present</p>
      </th> -->

      <th width="25%" valign="top" align="center">
      <a href="" target="_blank"><img src="assets/img/Cornell.png" alt="sym" width="45%"></a>
      <p style="line-height:1.3; font-size:12pt"><b>Cornell <br> University</b>
        <br>Ph.D. Student
        <br><a style="color:#808080">Aug. 23 - now</a>
      </p>
      </th>

      <th width="25%" valign="top" align="center">
      <a href="https://mitibmwatsonailab.mit.edu/" target="_blank"><img src="assets/img/logo_watson.png" alt="sym" width="45%"></a>
      <p style="line-height:1.3; font-size:12pt"><b>MIT-IBM <br> Watson  AI Lab</b>
        <br>Research Student
        <br><a style="color:#808080">Jul. 22 - Aug. 22</a>
        <!-- <br><a style="color:#808080">Dec. 20 - Aug. 21</a> -->
      </p>
      </th>

      <th width="25%" valign="top" align="center">
      <a href="https://en.nycu.edu.tw" target="_blank"><img src="assets/img/logo_NYCU.svg" alt="sym" width="45%"></a>
      <p style="line-height:1.3; font-size:12pt"><b>National Yang Ming <br> Chiao Tung University</b>
        <br>Doctor of Medicine
        <br><a style="color:#808080">Aug. 15 - Jun. 22</a>
      </p>
      </th>

      
      <!-- <th width="15%" valign="top" align="center">
      <a href="https://mitibmwatsonailab.mit.edu/" target="_blank"><img src="assets/img/ntu.png" alt="sym" width="45%"></a>
      <p style="line-height:1.3; font-size:12pt"><b>Vision & Learning Lab</b>
        <br>Research Assistant
        <br><a style="color:#808080">Dec. 22 - Jul. 23</a>
      </p>
      </th>

    
      <th width="15%" valign="top" align="center">
        <a href="https://walonchiu.github.io" target="_blank"><img src="assets/img/lab_2020_eva.png" alt="sym" width="62%"></a>
        <p style="line-height:1.3; font-size:12pt"><b>Enriched Vision Applications Lab</b>
          <br>Research Student
          <br><a style="color:#808080">Jul. 22 - Aug. 22</a>
        </p>
        </th> -->
  
      <!-- <th width="15%" valign="top" align="center">
      <a href="https://www.vghtpe.gov.tw/vghtpe/Index.action" target="_blank"><img src="assets/img/logo_TVGH.png" alt="sym" width="45%"></a>
      <p style="line-height:1.3; font-size:12pt"><b>Veterans General Hospital</b>
        <br>Intern Doctor
        <br><a style="color:#808080">Oct. 19 - Sep. 20</a>
        <br><a style="color:#808080">Jan. 22 - Jun. 22</a>
      </p>
      </th> -->


  </tr> 
  </tbody>
</table>



<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" style="margin-left:10px" >
  <!-- <p style="margin-left:30px"><small>PS: NYMU and NCTU merged to NYCU in Feb, 2021.<small></p> -->
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
  <tr><td>
    <sectionheading>&nbsp;&nbsp;News</sectionheading>
    <ul>
      <li> [2023/05] One paper on Federated Learning submitted to arXiv. </li>
      <li> [2022/12] Start working with NVIDIA Research Director Prof. <a href="http://vllab.ee.ntu.edu.tw/" target="_blank">Yu-Chiang Frank Wang</a>.</li>  
      <li> [2022/06] Pass the Taiwan Medical Licensing Examination.</li>
      <li> [2022/05] Complete the two-year medical internship in Taipei Veteran General Hospital, Taiwan.</li>
      <li> [2021/10] One paper accepted at <b>ICLR'22</b> as poster.</li>
      <li> [2021/10] One paper accepted at <b>NewInML Workshop, NeurIPS'21</b> as oral paper.</li>
      <li> [2021/06] One paper accepted at <b>MICCAI'21</b> as oral paper.</li>
      <li> [2020/12] Start working with Prof. <a href="https://walonchiu.github.io/" target="_blank"> Wei-Chen Chiu</a> and
        Dr. <a href="https://sites.google.com/site/pinyuchenpage" target="_blank">Pin-Yu Chen</a>.</li>
      <li> [2020/09] Start working with Prof. <a href="https://walonchiu.github.io/" target="_blank">Wei-Chen Chiu</a> and
        Prof. <a href="https://bml.ym.edu.tw/ibs/Members/LFChen-e.html" target="_blank"> Li-Fen Chen</a>.
    </ul>
  </td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>Publications</sectionheading></td></tr>
</table>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">

  <tr>
    <td width="33%" valign="top" align="center">
        <a href="assets/img/publications/NIPS2023_raw.webp" target="_blank">
        <img src="assets/img/publications/NIPS2023_raw.webp" width="100%" style="border-radius:5px">
        </a>
    </td>

    <td width="67%" valign="top", border="50" cellpadding="10", padding-left="30px";>
        <p>
            <!-- <a href="#" id="ICLR22"> -->
            <heading>FedBug: A Bottom-Up Gradual Unfreezing Framework for Federated Learning</heading>
            <br>
            <u>Chia-Hsiang Kao</u>, Yu-Chiang Frank Wang
            <br>
            | <a href="javascript:toggleblock('NIPS23_abs')">abstract</a> |
            <a href="https://arxiv.org/abs/2307.10317" target="_blank">arxiv</a> |
            <!-- <a href="https://iandrover.github.io/data/papers/ICLR2022_poster.pdf" target="_blank">poster</a> | -->
            <a href="https://github.com/IandRover/FedBug">github </a> |
            <!-- <a href="https://medium.com/@aaronkao/paper-maml-is-a-noisy-contrastive-learner-in-classification-de63001ad3e0">paper explained </a> | -->
          <!-- </a> -->
            <br>
            Submitted to arXiv.
            <!-- Accepted by <b>NeurIPS'21 workshop</b> as oral presentation. -->
            <!-- (Acceptance rate: 19.0%.) -->
        </p>
        <div class="paper" id="ICLR22">


        <p align="justify">
            <i id="NIPS23_abs" style="display:none">
              Federated Learning (FL) offers a collaborative training framework, allowing multiple clients to contribute to a shared model without compromising data privacy. Due to the heterogeneous nature of local datasets, updated client models may overfit and diverge from one another, commonly known as the problem of client drift. In this paper, we propose FedBug (Federated Learning with Bottom-Up Gradual Unfreezing), a novel FL framework designed to effectively mitigate client drift. FedBug adaptively leverages the client model parameters, distributed by the server at each global round, as the reference points for cross-client alignment. Specifically, on the client side, FedBug begins by freezing the entire model, then gradually unfreezes the layers, from the input layer to the output layer. This bottom-up approach allows models to train the newly thawed layers to project data into a latent space, wherein the separating hyperplanes remain consistent across all clients. We theoretically analyze FedBug in a novel over-parameterization FL setup, revealing its superior convergence rate compared to FedAvg. Through comprehensive experiments, spanning various datasets, training conditions, and network architectures, we validate the efficacy of FedBug. Our contributions encompass a novel FL framework, theoretical analysis, and empirical validation, demonstrating the wide potential and applicability of FedBug.
            </i>
        </p>
        </div>
    </td>
  </tr>

  <tr>
    <td width="33%" valign="top" align="center">
        <a href="assets/img/publications/ICLR2022_800x600.webp" target="_blank">
        <img src="assets/img/publications/ICLR2022_800x600.webp" alt="sym" width="100%" style="border-radius:5px">
        </a>
    </td>

    <td width="67%" valign="top", border="50" cellpadding="10", padding-left="30px";>
        <p>
            <!-- <a href="#" id="ICLR22"> -->
            <heading>MAML Is a Noisy Contrastive Learner in Classification</heading>
            <br>
            <u>Chia-Hsiang Kao</u>, Wei-Chen Chiu, Pin-Yu Chen
            <br>
            | <a href="javascript:toggleblock('ICLR22_abs')">abstract</a> |
            <a href="https://arxiv.org/abs/2106.15367" target="_blank">arxiv</a> |
            <a href="https://iandrover.github.io/data/papers/ICLR2022_poster.pdf" target="_blank">poster</a> |
            <a href="https://github.com/iandrover/maml_noisy_contrasive_learner">github </a> |
            <a href="https://medium.com/@aaronkao/paper-maml-is-a-noisy-contrastive-learner-in-classification-de63001ad3e0">paper explained </a> |
          <!-- </a> -->
            <br>
            Accepted by <b>ICLR'22</b> as poster.<br>
            Accepted by <b>NeurIPS'21 workshop</b> as oral presentation.
            <!-- (Acceptance rate: 19.0%.) -->
        </p>
        <div class="paper" id="ICLR22">


        <p align="justify">
            <i id="ICLR22_abs" style="display:none">
              Model-agnostic meta-learning (MAML) is one of the most popular and widely-adopted meta-learning algorithms nowadays, which achieves remarkable success in various learning problems. Yet, with the unique design of nested inner-loop and outer-loop updates which respectively govern the task-specific and meta-model-centric learning, the underlying learning objective of MAML still remains implicit and thus impedes a more straightforward understanding of it. In this paper, we provide a new perspective to the working mechanism of MAML and discover that: MAML is analogous to a meta-learner using a supervised contrastive objective function, where the query features are pulled towards the support features of the same class and against those of different classes, in which such contrastiveness is experimentally verified via an analysis based on the cosine similarity. Moreover, our analysis reveals that the vanilla MAML algorithm has an undesirable interference term originating from the random initialization and the cross-task interaction. We therefore propose a simple but effective technique, zeroing trick, to alleviate such interference, where the extensive experiments are then conducted on both miniImagenet and Omniglot datasets to demonstrate the consistent improvement brought by our proposed technique thus well validating its effectiveness.
            </i>
        </p>
        </div>
    </td>
  </tr>


    <tr>
        <td width="33%" valign="top" align="center">
            <a href="assets/img/publications/MICCAI2021_800x600.webp" target="_blank">
            <img src="assets/img/publications/MICCAI2021_800x600.webp" alt="sym" width="100%" style="border-radius:15px">
            </a>
        </td>

        <td width="67%" valign="top">
            <p>
              <!-- <a href="#" id="MICCAI21"> -->
                <heading>Demystifying T1-MRI to FDG18-PET Image Translation via Representational Similarity</heading>
                <br>
                <u>Chia-Hsiang Kao</u>, Yong-Sheng Chen, Li-Fen Chen, Wei-Chen Chiu
                <br>
                | <a href="javascript:toggleblock('MICCAI21_abs')">abstract</a> |
                <a href="data/papers/MICCAI2021.pdf" target="_blank">paper</a>|
                <br>
                Accepted by <b>MICCAI'21</b> as oral representation.
                <br>
                Earned the Student Travel Award in MICCAI'21.
            </p>
            <p align="justify">
                <i id="MICCAI21_abs" style="display:none">
                  Recent development of image-to-image translation techniques has enabled the generation of rare medical images (e.g., PET) from common ones (e.g., MRI). Beyond the potential benefits of the reduction in scanning time, acquisition cost, and radiation exposure risks, the translation models in themselves are inscrutable black boxes. In this work, we propose two approaches to demystify the image translation process, where we particularly focus on the T1-MRI to PET translation. First, we adopt the representational similarity analysis and discover that the process of T1-MR to PET image translation includes the stages of brain tissue segmentation and brain region recognition, which unravels the relationship between the structural and functional neuroimaging data. Second, based on our findings, an Explainable and Simplified Image Translation (ESIT) model is proposed to demonstrate the capability of deep learning models for extracting gray matter volume information and identifying brain regions related to normal aging and Alzheimer's disease, which untangles the biological plausibility hidden in deep learning models.
                </i>
            </p>
            </div>
        </td>
      </tr>


  	<tr>
      <td width="30%" valign="top" align="center">
        <a href="assets/img/publications/NER19_800x600.webp" target="_blank">
        <img src="assets/img/publications/NER19_800x600.webp" alt="sym" width="100%" style="border-radius:15px">
        </a>
      </td>

      <td width="70%" valign="top">
          <p>
              <!-- <a href="#" id="NER19"> -->
              <heading>Unravelling the Spatio-Temporal Neurodynamics of Rhythm Encoding-Reproduction Networks by a Novel fMRI Autoencoder</heading>
              <br>
              <u>Chia-Hsiang Kao</u>, Ching-Ju Yang, Li-Kai Cheng, Hsin-Yen Yu, Yong-Sheng Chen, Jen-Chuen Hsieh, and Li-Fen Chen
              <br>
              | <a href="javascript:toggleblock('NER19_abs')">abstract</a> |
              <a href="https://ieeexplore.ieee.org/document/8716917" target="_blank">paper</a> |
              <br>
              Accepted by <b>NER'19</b> as poster.
          </p>
          <p align="justify">
              <i id="NER19_abs" style="display:none">
                Visualization of how the external stimuli are processed dynamically in the brain would help understanding the neural mechanisms of functional segregation and integration. The present study proposed a novel temporal autoencoder to estimate the neurodynamics of functional networks involved in rhythm encoding and reproduction. A fully-connected two-layer autoencoder was proposed to estimate the temporal dynamics in functional magnetic resonance image recordings. By minimizing the reconstruction error between the predicted next time sample and the corresponding ground truth next time sample, the system was trained to extract spatial patterns of functional network dynamics without any supervision effort. The results showed that the proposed model was able to extract the spatial patterns of task-related functional dynamics as well as the interactions between them. Our findings suggest that artificial neural networks would provide a useful tool to resolve temporal dynamics of neural processing in the human brain.
              </i>
          </p>
          </div>
      </td>
    </tr>


    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
      <tr><td>
        <sectionheading>&nbsp;&nbsp;Awards and Scholarships</sectionheading>
        <ul>
          <li> [2021/06] <b>Student Travel Award</b>, MICCAI'21. <small>(To reward the best, e.g. highest scoring, first author students)</small></li>
          <li> [2020/08] <b>Undergraduate Research Fellowship</b>, National Science and Technology Council, Taiwan.</li>
          <li> [2018/08] <b>Undergraduate Research Fellowship</b>, National Science and Technology Council, Taiwan.</li>
          <li> [2018/06] <b>Summer Research Fellowship</b>, National Health Research Institutes and the Foundation of Health Sciences, Taiwan.</li>
        </ul>
      </td></tr>
    </table>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
      <tr><td>
        <sectionheading>&nbsp;&nbsp;Services</sectionheading>
        <ul>
          <li> [2022/08] <b>Reviewer</b>, Computer Vision and Image Understanding.</li>
          <li> [2022/04] <b>Reviewer</b>, AutoML'22 Conference.</li>
          <li> [2021/09] <b>Junior Reviewer</b>, Workshop on Meta-Learning, NeurIPS'21.</li>
        </ul>
      </td></tr>
    </table>

<!--     <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
      <tr><td>
        <sectionheading>&nbsp;&nbsp;Skills</sectionheading>
        <ul>
          <li> <b>Languages.</b> Mandarin (native), English (fluent, TOEFL:106/120).</li>
          <li> <b>Programming.</b> Python (Tensorflow, Pytorch, OpenCV, Scikit-Learn), Matlab.</li>
        </ul>
      </td></tr>
    </table> -->
<!-- 
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
      <tr><td>
        <sectionheading>&nbsp;&nbsp;Courses</sectionheading>
        <ul>
          <table width="100%" align="center" border="1" cellspacing="0" cellpadding="6">
            <tr>
              <td style="width:22%" align="center"><b>Mathematics</b></td>
              <td style="width:78%">Basic: Calculus, Probability, Linear Algebra°, Statistics°, Differential Equation°<br>
                  Analysis: Introduction to Analysis, Advanced Probability</td>
            </tr>
            <tr>
              <td align="center"><b>Machine Learning</b></td>
              <td>Machine Learning, Reinforcement Learning</td>
            </tr>
          </table>
          <p>° self-learn</p>
        </ul>
      </td></tr>
    </table> -->

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
      <tr><td>
        <sectionheading>&nbsp;&nbsp;Writings</sectionheading>
        <ul>
          <li>
            [2022/03]
            <a href="https://medium.com/@aaronkao/paper-maml-is-a-noisy-contrastive-learner-in-classification-de63001ad3e0#e9d4-d6ec57e3d08e" target="_blank">EN</a>
            <b>Paper Explained — MAML Is a Noisy Contrastive Learner in Classification</b>
          </li>
          <li>
            [2021/10]
            <a href="https://medium.com/@aaronkao/when-a-man-in-the-white-coat-codes-ii-c8035483ac35" target="_blank">EN</a>
            <b>When a Man in the White Coat Codes. (II)</b>
          </li>
          <li>
            [2021/09]
            <a href="https://hackmd.io/@A8e-o-EGSGq0GvfIVrSFYw/SJW561DQK#Two-understanding-of-the-Contrastive-Divergence-Algorithm" target="_blank">EN</a>
            <b>On Two Perspectives of Contrastive Divergence Algorithm.</b>
          </li>
          <li>
            [2021/08]
            <a href="https://medium.com/@aaronkao/self-stablization-and-life-7a5192b89f1b" target="_blank">CH</a>
            <b>Self-Stablization and Life.</b>
          </li>
          <li>
            [2021/02]
            <a href="https://medium.com/@aaronkao/when-a-man-in-the-white-coat-codes-7d740a2300e9" target="_blank">CH</a>
            <b>When a Man in the White Coat Codes.</b>
          </li>
          <li>
            [2020/06]
            <a href="https://medium.com/@aaronkao/%E8%A4%87%E9%9B%9C%E7%B3%BB%E7%B5%B1-a41b29b68c25" target="_blank">CH</a>
            <b>Complex System.</b></li>
          <li>
            [2020/06]
            <a href="https://medium.com/@aaronkao/gpt2-counting-consciousness-and-the-curious-hacker-%E4%B8%AD%E6%96%87%E7%BF%BB%E8%AD%AF-%E6%8C%91%E6%88%B0%E4%BF%A1%E4%BB%BB-gpt2%E5%92%8C%E5%A5%BD%E5%A5%87%E7%9A%84%E9%A7%AD%E5%AE%A2-5c018c78a09b" target="_blank">CH</a>
            <b>GPT2, Counting Consciousness and the Curious Hacker (挑戰信任：GPT2和好奇的駭客).</b>
          </li>
          <!-- <li>
            [2017/12]
            <a href="https://crossing.cw.com.tw/article/9184" target="_blank">CH</a>
            <b>我並不了解你／妳的世界──在「無知」是常態的世界，我們能否避免對彼此的傷害?</b>
          </li> -->
          <li>
            [2017/06]
            <a href="https://medium.com/@aaronkao/%E9%86%AB%E5%AD%B8%E4%BA%BA%E6%96%87%E5%AF%A6%E8%B8%90-%E7%B4%85%E7%B5%B2%E5%B8%B6%E7%B5%84-%E6%9C%9F%E6%9C%AB%E5%BF%83%E5%BE%97%E5%A0%B1%E5%91%8A-a5eed6b584e6" target="_blank">CH</a>
            <b>反思醫學人文實踐(課程).</b>
          </li>
          <li>
            [2017/05]
            <a href="https://medium.com/@aaronkao/could-a-neuro-scientist-understand-a-microprocessor-15f54e76a3fd" target="_blank">CH</a>
            <b>Could a Neuroscientist Understand a Microprocessor?</b>
          </li>
        </ul>
      </td></tr>
    </table>


    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
      <tr><td>
        <sectionheading>&nbsp;&nbsp;Interests</sectionheading>
        <ul>
          <p>I love swimming and got my lifeguard certification at 18.
          <br>I also enjoy surfing and jogging (one half-marathon, two 10Ks, and five 8.9Ks so far).
        </ul>
      </td></tr>
    </table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr><td><br><p align="right"><font size="2">
      Template: <a href="https://zswang666.github.io/" target="_blank">this</a>
      <br>
      Last update: Jul. 2023
    </font></p></td></tr>
</table>
  </td> </tr>
</table>

</script>
</body>

</html>
=======
<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Chia-Hsiang Kao</title> <meta name="author" content="Chia-Hsiang Kao"> <meta name="description" content="# A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. Taiwanese MD's journey as a Cornell CS PhD Student. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://iandrover.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/"><span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/"><span class="sr-only">(current)</span></a> </li> <li class="nav-item active"> <a class="nav-link" href="/repositories/"><span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="nav-item active"> <a class="nav-link" href="/teaching/"><span class="sr-only">(current)</span></a> </li> <li class="nav-item dropdown active"> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span class="sr-only">(current)</span></a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/projects/">projects</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Chia-Hsiang</span> Kao </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Aaron_23_08-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Aaron_23_08-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Aaron_23_08-1400.webp"></source> <img src="/assets/img/Aaron_23_08.jpg?625777b21d4634f26b20611253556d81" class="img-fluid z-depth-1 rounded-circle" width="auto" height="auto" alt="Aaron_23_08.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="clearfix"> <p>Hello, I’m a first-year Ph.D. student in Computer Science at Cornell University, and I also hold a medical license in Taiwan.</p> <p>I’ve had the privilege of collaborating with Dr. <a href="https://sites.google.com/site/pinyuchenpage" rel="external nofollow noopener" target="_blank">Pin-Yu Chen</a> at MTI-IBM Watson AI Lab, Prof. <a href="https://walonchiu.github.io/" rel="external nofollow noopener" target="_blank">Chiu-Wei Chen</a> and Prof. <a href="https://bml.ym.edu.tw/ibs/Members/LFChen-e.html" rel="external nofollow noopener" target="_blank">Li-Fen Chen</a> at NYCU, and NVIDIA Research Director Prof. <a href="http://vllab.ee.ntu.edu.tw/" rel="external nofollow noopener" target="_blank">Yu-Chiang Frank Wang</a>.</p> <p>My primary research interest lies in understanding the underlying mechanisms and implicit inductive biases of machine learning models and algorithms. I aspire to contribute to the development of robust and interpretable machine learning systems, designed to excel in challenging conditions.</p> </div> <h2><a href="/news/" style="color: inherit;">news</a></h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Jul 20, 2023</th> <td> Proud to announce our latest paper on federated learning, now available on arXiv! We’ve introduced an innovative algorithm that </td> </tr> <tr> <th scope="row">Apr 9, 2023</th> <td> Successfully completed a 210km relay marathon with nine of my incredible friends. Never stop running! </td> </tr> <tr> <th scope="row">Dec 1, 2022</th> <td> Proudly completed my four-month military service in Taiwan. </td> </tr> <tr> <th scope="row">Jun 26, 2022</th> <td> Successfully passed the Taiwan Medical Licensing Examination. I am now officially a licensed medical doctor. </td> </tr> </table> </div> </div> <h2><a href="/blog/" style="color: inherit;">latest posts</a></h2> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row">May 12, 2023</th> <td> <a class="news-title" href="/blog/2023/media/">Media</a> </td> </tr> <tr> <th scope="row">Oct 17, 2021</th> <td> <a class="news-title" href="/blog/2021/contrastive_divergence/">Contrastive_divergence</a> </td> </tr> </table> </div> </div> <h2><a href="/publications/" style="color: inherit;">selected publications</a></h2> <div class="publications"> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">arXiv</abbr></div> <div id="kao2023fedbug" class="col-sm-8"> <div class="title">FedBug: A Bottom-Up Gradual Unfreezing Framework for Federated Learning</div> <div class="author"> Chia-Hsiang Kao, and <a href="http://vllab.ee.ntu.edu.tw/members.html" rel="external nofollow noopener" target="_blank">Yu-Chiang Frank Wang</a> </div> <div class="periodical"> <em>arXiv preprint arXiv:2307.10317</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2307.10317" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/2023_arXiv.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p></p> </div> </div> </div> </li></ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ICLR</abbr></div> <div id="kao2022maml" class="col-sm-8"> <div class="title">MAML is a Noisy Contrastive Learner in Classification</div> <div class="author"> Chia-Hsiang Kao, <a href="https://walonchiu.github.io" rel="external nofollow noopener" target="_blank">Wei-Chen Chiu</a>, and <a href="https://sites.google.com/site/pinyuchenpage" rel="external nofollow noopener" target="_blank">Pin-Yu Chen</a> </div> <div class="periodical"> <em>In International Conference on Learning Representations</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2106.15367" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/2022_ICLR.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-altmetric-id="true"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p></p> </div> </div> </div> </li></ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">MICCAI</abbr></div> <div id="kao2021demystifying" class="col-sm-8"> <div class="title">Demystifying T1-MRI to FDG18-PET Image Translation via Representational Similarity</div> <div class="author"> Chia-Hsiang Kao, Yong-Sheng Chen, <a href="https://bmlab.web.nycu.edu.tw" rel="external nofollow noopener" target="_blank">Li-Fen Chen</a>, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Wei-Chen Chiu' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Medical Image Computing and Computer Assisted Intervention</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/abstract/document/8716917" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/2021_MICCAI.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.1109/NER.2019.8716917"></span> <span class="__dimensions_badge_embed__" data-doi="10.1109/NER.2019.8716917" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p></p> </div> </div> </div> </li></ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%63%6B%36%39%36_%61%74_%63%6F%72%6E%65%6C%6C_%64%6F%74_%63%6F%6D" title="email"><i class="fas fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=W_i9B0sAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/IandRover" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a> <a href="https://medium.com/@aaronkao" title="Medium" rel="external nofollow noopener" target="_blank"><i class="fab fa-medium"></i></a> <a href="/feed.xml" title="RSS Feed"><i class="fas fa-rss-square"></i></a> </div> <div class="contact-note"> Hello there! If you have any questions or just want to chat, don't hesitate to reach out. I'm always open to connecting with new people! </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Chia-Hsiang Kao. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>
>>>>>>> 2e41126bb7cdba840856651a185fd44234f5c554
