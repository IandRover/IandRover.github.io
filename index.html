<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
  /* Design Credits: Jon Barron and Abhishek Kar and Saurabh Gupta*/
  a {
  color: #1772d0;
  text-decoration:none;
  }
  a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
  }
  body,td,th {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 400
  }
  heading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 19px;
    font-weight: 1000
  }
  strong {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 800
  }
  strongred {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    color: 'red' ;
    font-size: 16px
  }
  sectionheading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    font-weight: 600
  }
  pageheading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 38px;
    font-weight: 400
  }
  </style>
  <link rel="icon" type="image/png" href="images/icon.png">
  <script type="text/javascript" src="js/hidebib.js"></script>
  <title>Chia-Hsiang Kao</title>
  <meta name="Chia-Hsiang Kao's Homepage" http-equiv="Content-Type" content="Chia-Hsiang Kao's Homepage">
  <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-GVN6RWCQKV"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-GVN6RWCQKV');
  </script>
  <!-- End : Google Analytics Code -->
  <!-- Scramble Script by Jeff Donahue -->
  <script src="js/scramble.js"></script>
</head>

<body>
<table width="840" border="0" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr><td>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <p align="center">
    <!-- <font size="7">Chia-Hsiang Kao</font><br> -->
    <pageheading>Chia-Hsiang Kao</pageheading><br>
    <b>email</b>: chkao.md04_at_nycu.edu.tw
    <font id="email" style="display:inline;">
      <noscript><i>Please enable Javascript to view</i></noscript>
    </font>
  </p>

  <tr>
    <td width="25%" valign="top"><a href="images/Aaron2.jpg"><img src="images/Aaron2.jpg" width="100%" style="border-radius:15px"></a>
        <p align=center>
            | <a href="https://iandrover.github.io/data/cv.pdf" target="_blank">CV</a> |
            <a href="https://github.com/IandRover" target="_blank">Github</a> |
            <br>
            |<a href="https://scholar.google.com.tw/citations?user=W_i9B0sAAAAJ" target="_blank">Google Scholar</a>|
        </p>
    </td>

    <td width="75%" valign="top" align="justify">
        <p>
        I am a medical student and will earn a medical license in June 2022!</p>
        <p>
        I was fortunate to have the opportunities to work with
        <a href="https://walonchiu.github.io/" target="_blank"> Prof. Wei-Chen Chiu</a> (National Yang Ming Chiao Tung University, NYCU) and
        <a href="https://sites.google.com/site/pinyuchenpage" target="_blank">Dr. Pin-Yu Chen</a> (IBM Researcher).
        Before that, I worked with <a href="https://bml.ym.edu.tw/ibs/Members/LFChen-e.html" target="_blank">Prof. Li-Fen Chen</a> (NYCU)
        and <a href="http://www.psynetresearch.org/people.html" target="_blank">Prof. Chih-Chieh (Albert) Yang </a> (NYCU).
        </p>
        <p></p>
        <p>
          My research interests encompass machine learning and its application in healthcare,
          especially computer vision, meta learing and model robustness.
          I desire to research on understanding the working mechanisms and deepening explainability of ML/DL models, and,
          as a long-term goal, to apply these novel understandings to improve and solve problems in healthcare.
        </p>
        <p>My Chinese name is 高家祥, which sounds like gao-jia-shang.</p>

        <!-- <p>Research interests: computer vision, medical image analysis, meta-learning, adversarial learning.</p> -->

        </td>
  </tr>
</table>



<!-- =================== Experience =================== -->
<table width="100%" align="center" style="margin-left:10px" cellspacing="0" cellpadding="0" border="0">
    <tr>
        <th width="16.6%" valign="top" align="center">
        <img src="images/VGH.png" alt="sym" width="60%"></a>
        <p style="line-height:1.3; font-size:12pt"><font size="1pt" style="line-height:1.3">Taipei Veteran General Hospital</font>
                                              Medical Intern<br>Oct. 21 - Jun. 22 <br> Oct. 19 - Sep. 20</p>
        </th>

        <th width="16.6%" valign="top" align="center">
        <img src="images/NCTU.png" alt="sym" width="60%"></a>
        <p style="line-height:1.3; font-size:12pt">NCTU<br>Visiting Scholar<br>Sep. 20 - Sep. 21</p>
        </th>

        <th width="16.6%" valign="top" align="center">
        <img src="images/Academia_Sinica.png" alt="sym" width="60%"></a>
        <p style="line-height:1.3; font-size:12pt">Academia Sinica<br>Summer Intern<br>Jul. 17 - Sep. 17</p>
        </th>

        <th width="16.6%" valign="top" align="center">
        <img src="images/NYMU.gif" alt="sym" width="60%"></a>
        <p style="line-height:1.3; font-size:12pt">NYMU<br>Student<br>Aug. 15 - Jun. 22</p>
        </th>

    </tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" style="margin-left:10px" >
  <p style="margin-left:30px">PS: NYMU and NCTU merged to NYCU in Feb, 2021</p>
</table>


<table width="100%" align="center" border="0" cellspacing="0" cellpadding="8">
  <tr><td>
    <sectionheading>&nbsp;&nbsp;News</sectionheading>
    <ul>
      <!-- <li> [05/2021] Start my research internship at <a href="https://research.snap.com/team/category/creative-vision/">Snap Research</a> working with
        <a href="http://hsinyinglee.com/">Hsin-Ying Lee</a> and <a href="http://www.stulyakov.com/">Sergey Tulyakov</a>.</li>
      <li> [02/2021] Start my graduate study at <b>CMU RI</b>!</li>
      <li> [07/2020] One paper accepted at <b>ECCV'20</b>.</li>
      <li> [03/2020] Start my research internship at Microsoft AI R&D Center, Taiwan working with
          <a href="http://www.cs.nthu.edu.tw/~lai/"> Prof. Shang-Hong Lai</a>.</li>
      <li> [09/2019] Start my visiting in <a href="http://vllab.ucmerced.edu/">VLLab</a> at UC Merced working with
          <a href="https://faculty.ucmerced.edu/mhyang/">Prof. Ming-Hsuan Yang</a>.</li> -->
      <!-- <li> [07/2019] One paper accepted at <b>ICCV'19</b>. See you at Seoul!</li> -->
      <li> [2021/11] Start second-year internship in Taipei Veteran General Hospital, Taiwan.</li>
      <li> [2021/16] One paper accepted at <b>MICCAI'21</b> as oral paper.</li>
      <li> [2020/12] Start working with <a href="https://walonchiu.github.io/" target="_blank"> Prof. Wei-Chen Chiu</a> and
            <a href="https://sites.google.com/site/pinyuchenpage" target="_blank">Dr. Pin-Yu Chen</a>.</li>
      <li> [2020/09] Start working with <a href="https://walonchiu.github.io/" target="_blank"> Prof. Wei-Chen Chiu</a> and
            <a href="https://bml.ym.edu.tw/ibs/Members/LFChen-e.html" target="_blank"> Prof. Li-Fen Chen</a>.
    </ul>
  </td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;Publications</sectionheading></td></tr>
</table>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">


  <tr>
    <td width="25%" valign="top" align="center">
        <a href="#">
        <!-- <img src="images/MICCAI2021.png" alt="sym" width="300" height="180" style="border-radius:15px"> -->
        </a>
    </td>

    <td width="75%" valign="top">
        <p>
            <!-- <a href="#" id="ICLR22"> -->
            <heading>MAML is a Noisy Contrastive Learner</heading>
          <!-- </a> -->
            <br>
            <u><b>Chia-Hsiang Kao</b></u>, Wei-Chen Chiu, Pin-Yu Chen
            <br>
            Summited to ICLR 2022
        </p>
        <div class="paper" id="ICLR22">
        <!-- <a href="https://yccyenchicheng.github.io/InOut/">webpage </a> | -->
        <a href="javascript:toggleblock('ICLR22_abs')">abstract</a> |
        <a href="https://arxiv.org/abs/2106.15367" target="_blank">arxiv</a>
        <!-- <a href="https://arxiv.org/abs/2104.00675">arXiv</a> | -->
        <!-- <a href="https://github.com/yccyenchicheng/InOut">code (coming soon)</a> -->
        <p align="justify">
            <i id="ICLR22_abs" style="display:none">
              Model-agnostic meta-learning (MAML) is one of the most popular and widely-adopted meta-learning algorithms nowadays, which achieves remarkable success in various learning problems. Yet, with the unique design of nested inner-loop and outer-loop updates which respectively govern the task-specific and meta-model-centric learning, the underlying learning objective of MAML still remains implicit and thus impedes a more straightforward understanding of it. In this paper, we provide a new perspective to the working mechanism of MAML and discover that: MAML is analogous to a meta-learner using a supervised contrastive objective function, where the query features are pulled towards the support features of the same class and against those of different classes, in which such contrastiveness is experimentally verified via an analysis based on the cosine similarity. Moreover, our analysis reveals that the vanilla MAML algorithm has an undesirable interference term originating from the random initialization and the cross-task interaction. We therefore propose a simple but effective technique, zeroing trick, to alleviate such interference, where the extensive experiments are then conducted on both miniImagenet and Omniglot datasets to demonstrate the consistent improvement brought by our proposed technique thus well validating its effectiveness.
            </i>
        </p>
        </div>
    </td>
  </tr>


    <tr>
        <td width="25%" valign="top" align="center">
            <a href="#">
            <img src="images/MICCAI2021.png" alt="sym" width="200" height="120"style="border-radius:15px">
            </a>
        </td>

        <td width="75%" valign="top">
            <p>
              <!-- <a href="#" id="MICCAI21"> -->
                <heading>Demystifying T1-MRI to FDG18-PET Image Translation via Representational Similarity</heading>
              <!-- </a> -->
                <br>
                <u><b>Chia-Hsiang Kao</b></u>, Yong-Sheng Chen, Li-Fen Chen, Wei-Chen Chiu
                <br>
                MICCAI 2021, oral representation
            </p>
            <div class="paper" id="MICCAI21">
            <!-- <a href="https://yccyenchicheng.github.io/InOut/">webpage </a> | -->
            <a href="javascript:toggleblock('MICCAI21_abs')">abstract</a> |
            <a href="data/papers/MICCAI2021.pdf" target="_blank">pdf</a>
            <!-- <a href="https://arxiv.org/abs/2104.00675">arXiv</a> | -->
            <!-- <a href="https://github.com/yccyenchicheng/InOut">code (coming soon)</a> -->
            <p align="justify">
                <i id="MICCAI21_abs" style="display:none">
                  Recent development of image-to-image translation techniques has enabled the generation of rare medical images (e.g., PET) from common ones (e.g., MRI). Beyond the potential benefits of the reduction in scanning time, acquisition cost, and radiation exposure risks, the translation models in themselves are inscrutable black boxes. In this work, we propose two approaches to demystify the image translation process, where we particularly focus on the T1-MRI to PET translation. First, we adopt the representational similarity analysis and discover that the process of T1-MR to PET image translation includes the stages of brain tissue segmentation and brain region recognition, which unravels the relationship between the structural and functional neuroimaging data. Second, based on our findings, an Explainable and Simplified Image Translation (ESIT) model is proposed to demonstrate the capability of deep learning models for extracting gray matter volume information and identifying brain regions related to normal aging and Alzheimer's disease, which untangles the biological plausibility hidden in deep learning models.
                </i>
            </p>
            </div>
        </td>
      </tr>


  	<tr>
      <td width="25%" valign="top" align="center">
          <a href="#">
          <!-- <img src="images/MICCAI2021.png" alt="sym" width="300" height="180" style="border-radius:15px"> -->
          </a>
      </td>

      <td width="75%" valign="top">
          <p>
              <!-- <a href="#" id="NER19"> -->
              <heading>Unravelling the Spatio-Temporal Neurodynamics of Rhythm Encoding-Reproduction Networks by a Novel fMRI Autoencoder</heading>
            <!-- </a> -->
              <br>
              <u><b>Chia-Hsiang Kao</b></u>, Ching-Ju Yang, Li-Kai Cheng, Hsin-Yen Yu, Yong-Sheng Chen, Jen-Chuen Hsieh, and Li-Fen Chen
              <br>
              International IEEE/EMBS Conference on Neural Engineering (NER) 2019
          </p>
          <div class="paper" id="NER19">
          <!-- <a href="https://yccyenchicheng.github.io/InOut/">webpage </a> | -->
          <a href="javascript:toggleblock('NER19_abs')">abstract</a> |
          <a href="https://ieeexplore.ieee.org/document/8716917" target="_blank">link</a>
          <!-- <a href="https://arxiv.org/abs/2104.00675">arXiv</a> | -->
          <!-- <a href="https://github.com/yccyenchicheng/InOut">code (coming soon)</a> -->
          <p align="justify">
              <i id="NER19_abs" style="display:none">
                Visualization of how the external stimuli are processed dynamically in the brain would help understanding the neural mechanisms of functional segregation and integration. The present study proposed a novel temporal autoencoder to estimate the neurodynamics of functional networks involved in rhythm encoding and reproduction. A fully-connected two-layer autoencoder was proposed to estimate the temporal dynamics in functional magnetic resonance image recordings. By minimizing the reconstruction error between the predicted next time sample and the corresponding ground truth next time sample, the system was trained to extract spatial patterns of functional network dynamics without any supervision effort. The results showed that the proposed model was able to extract the spatial patterns of task-related functional dynamics as well as the interactions between them. Our findings suggest that artificial neural networks would provide a useful tool to resolve temporal dynamics of neural processing in the human brain.
              </i>
          </p>
          </div>
      </td>
    </tr>


    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="8">
      <tr><td>
        <sectionheading>&nbsp;&nbsp;Services, awards and scholarships</sectionheading>
        <ul>
          <li> [2021] <b>Junior Reviewer</b>, Workshop on Meta-Learning, NeurIPS.</li>
          <li> [2021] <b>Student Travel Award</b>, MICCAI 2021. <small>(To reward the best, e.g. highest scoring, first author students)</small></li>
          <li> [2020] <b>College Student Research Scholarships</b>, Ministry of Science and Technology, Taiwan.</li>
          <li> [2018] <b>College Student Research Scholarships</b>, Ministry of Science and Technology, Taiwan.</li>
          <li> [2018] <b>Summer Research Scholarships</b>, National Health Research Institutes and the Foundation of Health Sciences, Taiwan.</li>
        </ul>
      </td></tr>
    </table>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="8">
      <tr><td>
        <sectionheading>&nbsp;&nbsp;Skills and courses</sectionheading>
        <ul>
          <li> <b>Languages.</b> Python, Matlab, Linux, HTML</li>
          <li> <b>Mathematics courses.</b> Introduction to Analysis, Honor Class (A-), Advanced Probability (A)</li>
          <li> <b>ML/DL courses.</b> Machine Learning (A+), Reinforcement Learning (A+)</li>
          <li> <b>ML/DL.</b> Tensorflow, Pytorch, OpenCV, Scikit-Learn</li>
        </ul>
      </td></tr>
    </table>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="8">
      <tr><td>
        <sectionheading>&nbsp;&nbsp;Writings</sectionheading>
        <ul>
          <li>
            <a href="https://hackmd.io/@A8e-o-EGSGq0GvfIVrSFYw/SJW561DQK#Two-understanding-of-the-Contrastive-Divergence-Algorithm" target="_blank">Link</a>
            2021-09.
            <b>Two understanding of the Contrastive Divergence Algorithm.</b>
          </li>
          <li>
            <a href="https://medium.com/@aaronkao/self-stablization-and-life-7a5192b89f1b" target="_blank">Link</a>
            2021-08.
            <b>Self-stablization and Life.</b>
          </li>
          <li>
            <a href="https://medium.com/@aaronkao/%E8%A4%87%E9%9B%9C%E7%B3%BB%E7%B5%B1-a41b29b68c25" target="_blank">Link</a>
            2020-06.
            <b>複雜系統</b></li>
          <li>
            <a href="https://medium.com/@aaronkao/gpt2-counting-consciousness-and-the-curious-hacker-%E4%B8%AD%E6%96%87%E7%BF%BB%E8%AD%AF-%E6%8C%91%E6%88%B0%E4%BF%A1%E4%BB%BB-gpt2%E5%92%8C%E5%A5%BD%E5%A5%87%E7%9A%84%E9%A7%AD%E5%AE%A2-5c018c78a09b" target="_blank">Link</a>
            2020-06.
            <b>GPT2, Counting Consciousness and the Curious Hacker (挑戰信任：GPT2和好奇的駭客)</b>
          </li>
          <li>
            <a href="https://crossing.cw.com.tw/article/9184" target="_blank">Link</a>
            2017-12.
            <b>我並不了解你／妳的世界──在「無知」是常態的世界，我們能否避免對彼此的傷害？</b>
          </li>
        </ul>
      </td></tr>
    </table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr><td><br><p align="right"><font size="2">
      Template: <a href="https://zswang666.github.io/" target="_blank">this</a>
      <br>
      Last update: Oct, 2021
    </font></p></td></tr>
</table>
  </td> </tr>
</table>

<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>

<script xml:space="preserve" language="JavaScript">
  hideblock('MICCAI21_abs');
</script>

<script xml:space="preserve" language="JavaScript">
  hideblock('infinitygan21_abs');
</script>

<script xml:space="preserve" language="JavaScript">
  hideblock('segvae20_abs');
</script>


<script xml:space="preserve" language="JavaScript">
hideblock('iccv19_abs');
</script>

<script xml:space="preserve" language="JavaScript">
hideblock('neuripsw18_abs');
</script>

</script>
</body>

</html>
