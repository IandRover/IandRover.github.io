#### Introduction
 I am a medical student at National Yang Ming Chiao Tung University with research interests in machine learning, computer vision and medical image analysis. My recent research direction involves (gradient-based) Meta-Learning (please refer to my publication) and Adversarial Learning.
 I am looking for PHD (from 2023 Spring) in ML/DL, neuroscience or bio-engineering. <br><br>

#### Research Interests
My research direction has always remained the same: diving into the fundamental problems to understand the inner working mechanisms of deep learning models, and to apply the (novel) understanding to practical tasks.
- My first publication in NER conference (International IEEE/EMBS Conference on Neural Engineering) aims to use the spatial-temporal encoder to unravel the patterns in fMRI.
- The oral paper in MICCAI: Initially, I am intrigued by the increasing trend in using GAN to translate medical images. But I found none of the current work discusses the reason why deep learning models can achieve so, and they rather treat the models as black-boxes. As exploration, after implementation and applying extensive visualization tools (GradCAM, filter visualization, building additional attention modules), I propose that the models may implicitly perform brain region and brain tissue recognition. Finally, we use Canonical Component Analysis to finish this work.
- Currently under review in NIPS 2021, my new paper turns to MAML (model-agnostic meta learning algorithm) and we find that the bilevel-optimization procedure of MAML can be understood from a supervised contrastive learning point of view. Based on our theoretical results, we further improve the MAML algorithm by introducing a zeroing trick.

 My next move is to explore the min-max problem that are intensively encountered in adversarial learning. This is mainly because of the fact that during my research in MAML, I become more familiar with the bi-level optimization.

I thank all the supervisors for their inspiring suggestion and the reviewers for their insightful comments. These studies cannot be done without their engagements. <br><br>

#### Future Plan
I would like to pursue PHD (from 2023 Spring) after graduation from the medical school. I am currently looking for labs that welcomes people from interdisciplinary background. <br><br>

### <i class="fa fa-chevron-right"></i> Education
<table class="table table-hover">
  <tr>
    <td>
        <strong>Doctor of Medicine</strong> (M.D.)
          <!-- (0.00/0.00) -->
        <br>
      National Yang Ming Chiao Tung University | Taipei, Taiwan
        <p style='margin-top:-1em;margin-bottom:0em' markdown='1'>
        <!-- <br> *<a href="https://github.com/bamos/thesis">Differentiable Optimization-Based Modeling for Machine Learning</a>* -->
        <br> Advisors:
        <a href="https://scholar.google.com.tw/citations?user=BJjT9kAAAAAJ">Li-Fen, Chen </a> (2017 - 2020), <a href="https://walonchiu.github.io/"> Wei-Chen Chiu</a> (2020 - 2021), <a href="https://sites.google.com/site/pinyuchenpage">Pin-Yu Chen</a> (2021)  
        </p>
    </td>
    <td class="col-md-2" style='text-align:right;'>2015 - 2022</td>
  </tr>
</table>


### <i class="fa fa-chevron-right"></i> Research Internship
<table class="table table-hover">
<tr>
  <td>
<p markdown="1" style='margin: 0'>
<strong>Institute of Information Science, Academia Sinica</strong>
| Taipei, Taiwan
| Host: <a href="https://homepage.iis.sinica.edu.tw/pages/mcc/index_en.html">Meng Chang, Chen</a>
</p>
  </td>
  <td class='col-md-2' style='text-align:right;'>2017</td>
</tr>

<!-- <tr>
  <td>
  </td>
  <td class='col-md-2' style='text-align:right;'>2014</td>
</tr> -->
</table>

### <i class="fa fa-chevron-right"></i> Courses
<table class="table table-hover">

<tr>
  <td><strong>Course name</strong></td>
  <td style='text-align:center;'><strong>Score</strong></td>
  <!-- <td class='col-md-2' style='text-align:left;'>Institute of Applied Mathematics</td> -->
</tr>

<tr>
  <td><strong>Introduction to Analysis, Honor Class <br> </strong>Institute of Mathematics, NYVU</td>
  <td style='text-align:center;'>A-</td>
  <!-- <td class='col-md-2' style='text-align:left;'>Institute of Applied Mathematics</td> -->
</tr>

<tr>
  <td><strong>Advanced Probability <br> </strong>Institute of Mathematics, NYVU</td>
  <td style='text-align:center;'>A-</td>
  <!-- <td class='col-md-2' style='text-align:left;'>Institute of Applied Mathematics</td> -->
</tr>

<tr>
  <td><strong>Reinforcement Learning</strong></td>
  <td style='text-align:center;'>A+</td>
  <!-- <td class='col-md-2' style='text-align:left;'>Institue of Computer Science and Engineering</td> -->
</tr>

<tr>
  <td><strong>Machine Learning</strong></td>
  <td style='text-align:center;'>A+</td>
  <!-- <td class='col-md-2' style='text-align:left;'>Institue of Computer Science and Engineering</td> -->
</tr>

<tr>
  <td><strong>Molecular Simulation: Concepts and Applications</strong></td>
  <td style='text-align:center;'>A+</td>
  <!-- <td class='col-md-2' style='text-align:left;'>Institue of Computer Science and Engineering</td> -->
</tr>

<tr>
  <td><strong>Theory of Computability</strong></td>
  <td style='text-align:center;'>A+</td>
  <!-- <td class='col-md-2' style='text-align:left;'>Institue of Computer Science and Engineering</td> -->
</tr>

<tr>
  <td><strong>Introduction to Computer Science</strong></td>
  <td style='text-align:center;'>A+</td>
  <!-- <td class='col-md-2' style='text-align:left;'>Institue of Computer Science and Engineering</td> -->
</tr>


</table>


### <i class="fa fa-chevron-right"></i> Honors & Awards
<table class="table table-hover">
<tr>
  <td>
    <strong>College Student Research Scholarship</strong>, MOST, Taiwan
    <br>
  </td>
  <td class='col-md-2' style='text-align:right;'> 2020 </td>
</tr>
<tr>
  <td>
    <strong>Second Prize</strong>, Taiwan Brain Tumor Segmentation Challenge
  </td>
  <td class='col-md-2' style='text-align:right;'> 2019 </td>
</tr>
<tr>
  <td>
    <strong>College Student Research Scholarship</strong>, MOST, Taiwan
    <br>
  </td>
  <td class='col-md-2' style='text-align:right;'> 2018 </td>
</tr>
<tr>
  <td>
    <strong>Gold Medal</strong>, International Genetically Engineered Machine Competition
    <br>
  </td>
  <td class='col-md-2' style='text-align:right;'> 2016 </td>
</tr>
</table>


### <i class="fa fa-chevron-right"></i> Publications

<h2>2021</h2>
<table class="table table-hover">

<tr id="tr-kao2021maml" style="background-color: #ffffd0">
<td>
    <em><a href='https://arxiv.org/abs/2106.15367' target='_blank'>MAML is a Noisy Contrastive Learner</a> </em><br>
    <strong>Chia-Hsiang Kao</strong>, Wei-Chen Chiu, and Pin-Yu Chen<br>
    Preprint
[<a href='javascript:;'
    onclick='$("#abs_kao2021maml").toggle()'>abs</a>]
     <!-- [<a href='https://github.com/facebookresearch/dcem' target='_blank'>code</a>]  -->
    <!-- [<a href='http://bamos.github.io/data/slides/2020.dcem.pdf' target='_blank'>slides</a>] <br> -->

<div id="abs_kao2021maml" style="text-align: justify; display: none" markdown="1">
Model-agnostic meta-learning (MAML) is one of the most popular and widely-adopted meta-learning algorithms nowadays, which achieves remarkable success in various learning problems.
Yet, with the unique design of nested inner-loop and outer-loop updates which respectively govern the task-specific and meta-model-centric learning,
the underlying learning objective of MAML still remains implicit and thus impedes a more straightforward understanding of it.
In this paper, we provide a new perspective to the working mechanism of MAML and discover that: MAML is analogous to a meta-learner using a supervised contrastive objective function, where the query features are pulled towards the support features of the same class and against those of different classes, in which such contrastiveness is experimentally verified via an analysis based on the cosine similarity. Moreover, our analysis reveals that the vanilla MAML algorithm has an undesirable interference term originating from the random initialization and the cross-task interaction. We therefore propose a simple but effective technique, zeroing trick, to alleviate such interference, where the extensive experiments are then conducted on both miniImagenet and Omniglot datasets to demonstrate the consistent improvement brought by our proposed technique thus well validating its effectiveness.
</div>

</td>
</tr>

<tr id="tr-kao2021demystifying" style="background-color: #ffffd0">
<td>
    <em>Demystifying T1-MRI to FDG18-PET Image Translation via Representational Similarity</em> <br>
    [Oral presentation] <br>
    <strong>Chia-Hsiang Kao</strong>, Wei-Chen Chiu, and Pin-Yu Chen<br>
    MICCAI 2021
    [<a href='javascript:;'
    onclick='$("#abs_kao2021demystifying").toggle()'>abs</a>]
     <!-- [<a href='https://github.com/facebookresearch/dcem' target='_blank'>code</a>]  -->
    <!-- [<a href='http://bamos.github.io/data/slides/2020.dcem.pdf' target='_blank'>slides</a>] <br> -->

<div id="abs_kao2021demystifying" style="text-align: justify; display: none" markdown="1">
Recent development of image-to-image translation techniques has enabled the generation of rare medical images (e.g., PET) from common ones (e.g., MRI). Beyond the potential benefits of the reduction in scanning time, acquisition cost, and radiation exposure risks, the translation models in themselves are inscrutable black boxes. In this work, we propose two approaches to demystify the image translation process, where we particularly focus on the T1-MRI to PET translation. First, we adopt the representational similarity analysis and discover that the process of T1-MR to PET image translation includes the stages of brain tissue segmentation and brain region recognition, which unravels the relationship between the structural and functional neuroimaging data. Second, based on our findings, an Explainable and Simplified Image Translation (ESIT) model is proposed to demonstrate the capability of deep learning models for extracting gray matter volume information and identifying brain regions related to normal aging and Alzheimer's disease, which untangles the biological plausibility hidden in deep learning models.
</div>

</td>
</tr>


</table>

<h2>2019</h2>
<table class="table table-hover">
<tr id="tr-Kao2019Unravelling" style="background-color: #ffffd0">
<td>
    <em><a href='https://ieeexplore.ieee.org/document/8716917' target='_blank'>Unravelling the Spatio-Temporal Neurodynamics of Rhythm Encoding-Reproduction Networks by a Novel fMRI Autoencoder</a> </em><br>
    <strong>Chia-Hsiang Kao</strong>, Ching-Ju Yang, Li-Kai Cheng, Hsin-Yen Yu, Yong-Sheng Chen, Jen-Chuen Hsieh, and Li-Fen Chen<br>
    NER 2019
    [<a href='javascript:;'
    onclick='$("#abs_Kao2019Unravelling").toggle()'>abs</a>]
    <!-- [<a href='https://github.com/facebookresearch/svg' target='_blank'>code</a>]   -->
    <!-- [<a href='http://bamos.github.io/data/slides/2021.svg.pdf' target='_blank'>slides</a>]   -->
    <!-- [<a href='https://youtu.be/ABS40GW7Ekk?t=5393' target='_blank'>talk</a>] <br> -->

<div id="abs_Kao2019Unravelling" style="text-align: justify; display: none" markdown="1">
Visualization of how the external stimuli are processed dynamically in the brain would help understanding the neural mechanisms of functional segregation and integration. The present study proposed a novel temporal autoencoder to estimate the neurodynamics of functional networks involved in rhythm encoding and reproduction. A fully-connected two-layer autoencoder was proposed to estimate the temporal dynamics in functional magnetic resonance image recordings. By minimizing the reconstruction error between the predicted next time sample and the corresponding ground truth next time sample, the system was trained to extract spatial patterns of functional network dynamics without any supervision effort. The results showed that the proposed model was able to extract the spatial patterns of task-related functional dynamics as well as the interactions between them. Our findings suggest that artificial neural networks would provide a useful tool to resolve temporal dynamics of neural processing in the human brain.
</div>

</td>
</tr>

</table>

### <i class="fa fa-chevron-right"></i> Repositories
<table class="table table-hover">
<tr>
  <td>
    <a href="https://github.com/IandRover/meta-gradient_RL">Replication</a>
    <!-- |<i class="fa fas fa-star"></i> 377 | -->
    <em>NeurIPS 2018 "Meta-Gradient Reinforcement Learning"</em>
    <!--  -->
    <!--     facebookresearch/mbrl-lib  -->
    <!--  -->
  </td>
  <td class='col-md-1' style='text-align:right;'>2021</td>
</tr>
</table>

### <i class="fa fa-chevron-right"></i> Volumteer Experience
<table class="table table-hover">
<tr>
  <td>
    <strong>Leading data analyst</strong> <br>
    Data for Social Good Program, DSP Inc, Taiwan <br>
  </td>
  <td class='col-md-2' style='text-align:right;'> 2018 </td>
</tr>
</table>

<!-- ### Test -->
<!-- <div class="topnav">
  <a class="active" href="#home">Home</a>
  <a href="#Awards">Awards</a>
  <a href="#Certification">Certification</a>
  <a href="#about">About</a>
</div>

<div class="tab-content">
  <div class="tab-pane container active" id="Awards">
    <h6>
    <br>
    <li><a href="#" data-toggle="modal" data-target="#MOSTModal">College Student Research Scholarship, MOST, Taiwan, 2018~2019</a></li><br>
    <li>Academic Achievement Award, University of Taipei, Taiwan, 2015~2018</li><br>
    <li><a href="http://service.utaipei.edu.tw/files/11-1023-59.php?Lang=zh-tw">Entrance Scholarship, University of Taipei, Taiwan, 2015~2018</a></li><br>
    <li>Literary Award, National Yilan Senior High School, Yilan, Taiwan, 2013~2014</li><br>
    <li>Academic Achievement Award, National Yilan Senior High School, Yilan, Taiwan, 2013~2014</li>
    <br>
    </h6>
  </div>
  <div class="tab-pane container fade" id="Certification">
    <h6>
    <br>
    <li>初階行銷傳播認證, <a href="http://www.tmca.org.tw/">TMCA</a>, Taiwan Marcom Certification Association, 2015</li><br>
    <li>TOEIC Score:685, ETS, 2015</li><br>
    <li>The General English Proficiency Test Intermediate,<a href="https://www.lttc.ntu.edu.tw/E_LTTC/E_GEPT.htm"> LTTC</a>, 2015</li>
    <br>
    </h6>
  </div> -->

  ### test2
<!-- abs plugin also works with pil -->
<ul class="topnav" >
  <!-- <li class="nav-item"> -->
    <a class="active" href="#home">Home</a>
  <!-- </li> -->
  <!-- <li class="nav-item"> -->
  <a href="#profile">profile</a>
  <!-- </li> -->
  <!-- <li class="nav-item"> -->
  <a href="#hi">hi</a>
  </li>
</ul>

<div class="tab-content" id="Home">
  <div class="tab-pane fade show active" id="home">welcome home</div>
  <div class="tab-pane fade" id="profile">welcome file</div>
  <div class="tab-pane fade" id="contact">welcome contact</div>
</div>


### <i class="fa fa-chevron-right"></i> Skills
<table class="table table-hover">
<tr>
  <td class='col-md-2'>Languages</td>
  <td> Python, Matlab
  </td>
</tr>
<tr>
  <td class='col-md-2'>Frameworks</td>
  <td> NumPy, Pandas, PyTorch, SciPy, TensorFlow
  </td>
</tr>
<tr>
  <td class='col-md-2'>Tools</td>
  <td> Linux, tmux
  </td>
</tr>
</table>
